{
  "hash": "96034785b18a23aa026e46d7baa15726",
  "result": {
    "markdown": "---\ntitle: \"Bayesian Power Analyse\"\ndescription: \"Hier een geinige beschrijving\"\ndate: 01-01-2024\ncategories: \n  - keywords\n  - bla\n  - blabla\ndraft: false\n\n---\n\n\n\n# Inleiding\n\nZorgverzekeraar VGZ en enkele huisartsen uit de zorggroep Syntein starten met een experimentele vorm van bekostiging die past bij het werken met [Positieve Gezondheid](https://www.iph.nl/positieve-gezondheid/wat-is-het/). De interventiepraktijken zullen in het experiment bekostigd worden met een volledige abonnementsbekostiging. We verwachten dat bij deze praktijken het aantal verwijzingen naar de tweedelijnszorg lager zal zijn dan bij de controlepraktijken die zijn aangewezen voor deze studie. In dit document leggen we uit hoe we, ondanks een relatief beperkte aantal interventiepraktijken, via Bayesiaanse analyse het effect van de interventie gaan vaststellen. We starten met een uitleg van de principes van Bayesiaanse statistiek en laten daarna stap voor stap zien hoe we de data en analyse opbouwen. We visualeren de resultaten en laten zien hoe deze veranderen met andere uitgangspunten. De installatie instructies beschrijven hoe je dit document zelf kunt reproduceren. Dit document beschrijft alleen de analyses, de bredere onderzoeksopzet staat in een apart document beschreven. \n\nNB: dit onderzoek is een vervolg op een eerder experiment waarbij alleen de huisartsenpraktijk Afferden via een volledig abonnementstarief is bekostigd. In dit stuk referen we soms naar de bevindingen van dit experiment. De onderzoeksresulten zijn [hier gepubliceerd](https://research.tilburguniversity.edu/en/publications/beyond-the-clock-exploring-the-causal-relationship-between-genera).\n\n## De principes van Bayesiaanse analyse\nWe gebruiken de principes van Bayesiaanse analyse om de effectiviteit van een de abonnementsbekostiging bij een aantal Syntein huisartsenpraktijken te beoordelen. We werken met een beperkt aantal datapunten. In tegenstelling tot traditionele significatietesten, waarbij de focus ligt op het bepalen of een effect wel of niet statistisch significant is, richt onze Bayesiaanse analyse zich op het inschatten van de waarschijnlijkheid dat de interventie daadwerkelijk een bepaald effect heeft. \n\nBij Bayesiaanse analyse beginnen we met het expliciet uitspreken van de verwachting die we hebben over het effect van het experiment. Dit is de initiële overtuiging, ook wel een \"prior\" genoemd. Hoewel we theoretisch gezien verwachten dat het aantal verwijzingen af zal nemen bij de interventiepraktijken, hebben we hier nog geen bewijs van gezien. We formuleren daarom onze prior conservatief en stellen dat de interventie geen effect heeft, met een behoorlijke mate van onzekerheid. Dat wil zeggen dat we in eerste instantie veronderstellen dat de kans op een positief effect (minder verwijzingen) even groot is als een negatief effect (meer verwijzingen). \n\nDaarna gaan we gegevens verzamelen. Op basis van deze data passen we onze overtuiging aan. De aangepaste overtuiging is uitgedrukt in de zogenoemde 'posterior'. De posterior geeft de kans dat de interventie een effect heeft, rekening houdend met zowel onze initiele overtuiging (de prior) als de data. In andere woorden: de posterior is een mix van de prior en de data. Naar mate we meer data verzamelen zal de prior minder invloed op de waarde van de posterior hebben (We kunnen bijvoorbeeld meer data krijgen door interventie- en controlepraktijken toe te voegen, of wanneer we overstappen naar een analyse op patientniveau). \n\nJe zult in het eerste deel van deze simulatie zien dat onze conservatief gestelde prior (we verwachten geen effect) zorgt dat de posterior iets lager uitvalt dan het werkelijke effect. We laten ook zien dat bij een overdreven optimistische prior (we verwachten een groter effect dan er feitelijk is) de posterior iets hoger uitvalt dan het werkelijke effect. Deze verschillen zijn echter gering als we voldoende onzekerheid in onze priors meenemen. Dat blijkt in het tweede deel van de simulatie.\n\nKortom, het gebruik van Bayesiaanse analyse stelt ons in staat om te werken met beperkte gegevens en toch bruikbare inzichten te verkrijgen over de waarschijnlijkheid van een interventie-effect. Dit is vooral relevant in situaties waarin het moeilijk is om voldoende datapunten te verzamelen om traditionele significante testen uit te voeren. Door de focus te verleggen van enkel significantie naar waarschijnlijkheid, kunnen we beter omgaan met onzekerheid en variabiliteit in onze resultaten.\n\n# Hoe werkt de simulatie?\n\n## Basis data genereren op basis van parameters\nWe gebruiken de controlepraktijken uit een eerder onderzoek van Afferden  voor het genereren van de data in deze simulatie. Deze praktijken hadden ongeveer 0.35 tot 0.45 verwijzingen per ingeschreven patient, met een standaarddeviatie (spreiding) van 0.02. We genereren op basis van deze parameters een dataset die dient als onze \"basis data\". De controlepraktijken krijgen een willekeurig aantal verwijzingen tussen de 0.37 en 0.43. De interventiepraktijken krijgen een vast aantal van 0.40 verwijzingen. Doordat we een vaste waarde aanhouden bij de interventieprakijken kunnen we straks het effect makkelijk relateren aan de startwaarde. \n\n## Invoegen van een effect\nAan deze basis data voegen we handmatig een effect toe om de interventie te simuleren. We voegen bijvoorbeeld een effect toe van -0.04 (het aantal verwijzingen per patient neemt af met 0.04). Als je dit relateert aan de startwaarde van de interventiepraktijken (0.4) dan zie je een afname van 10% (0.04/0.4).\n\n## Bayesiaanse regressie\nNa het inbrengen van het effect, voeren we een Bayesiaanse regressie uit op de dataset. Op basis van de resultaten van de regressie kunnen beoordelen we in hoeverre we het effect correct en nauwkeurig hebben geschat, gegeven de inherente ruis en variabiliteit in de data. \n\nDe deelnemende partijen in het onderzoek kunnen ervoor kiezen om een bepaald minimum effect te willen behalen (en bijvoorbeeld af te spreken om het experiment te stoppen wanneer dit niet bereikt wordt). We laten daarom ook zien hoe de resultaten gebruikt kunnen worden om de zekerheid te bepalen rondom het behalen van dit minimum effect. De waarschijnlijkheid van het behalen van het minimum effect (gegeven de inherente ruis en variabiliteit in de data) wordt weergegeven in een kansverdeling. \n\n## Herhaalde analyse\n\nWe doen de regressie niet 1 x, maar herhalen deze meerdere keren. Bij elke herhaling (iteratie) genereren we opnieuw een dataset, waarbij we blijven werken met dezelfde parameters. Hierdoor krijgen we een reeks resultaten die de stabiliteit en reproduceerbaarheid van onze analyse illustreren. De herhalingen helpen ons te begrijpen hoe effectief en betrouwbaar onze analyse is bij het schatten van effecten en het beoordelen van kansen, zelfs in situaties waarin er beperkte datapunten beschikbaar zijn.\n\n## Laatste opmerking\nTenslotte willen we opmerken dat we deze simulatie hebben geschreven voor het totaal aantal verwijzingen, omdat we daar uit eerder onderzoek informatie over hadden. We verwachten dat andere interessante uitkomsten (bijvoorbeeld subcategorien van verwijzingen) veel meer ruis bevatten dan het totaal aantal verwijzingen. Maar we kunnen pas echt een goede simulatie te doen als we de verwijzingen van de relevante praktijken hebben.\n\n# Wat kunnen we veranderen in deze simulatie\n\nHet is mogelijk om deze simulatie zelf te runnen en veranderingen aan te brengen. In deze paragraaf beschrijven we kort wat er nodig is om deze simulatie zelf te kunnen runnen. Je kunt alle waarden in de codeblokjes van dit hoofdstuk zelf aanpassen en kijken wat het effect is op de resultaten.\n\nEr is (gratis) software nodig. De instructies om dat te installeren vind je onderaan dit notebook.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# packages en settings\n\nknitr::opts_chunk$set(eval = TRUE, warning = FALSE, message = FALSE)\n\nscipen = 999\n\n# Packages installeren -> hoeft maar 1 keer, daarna kunnen ze geladen worden\n\n# install.packages(c(\"tidyverse\", \"ggridges\", \"brms\"))\n\n# Laden packages\n\nlibrary(tidyverse) # data wrangling en plots\nlibrary(ggridges) # voor plotjes posterior\nlibrary(brms) # voor bayesiaanse analyse (interface naar Stan)\n```\n:::\n\n\n\n## Aantal praktijken\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Kies aantal interventie praktijken\n\nIP <- 2\n\n# Kies aantal controle praktijken\n\nCP <- 3\n```\n:::\n\n\n\nWe hebben 2 interventie en 3 controlepraktijken. Dit aantal kan in het codeblokje \"aantal praktijken\" hierboven worden aangepast. In de basisdata die hieronder worden gegenereerd, kiezen we voor een gemiddeld aantal verwijzingen per patient van ongeveer 0.4 met een spreiding van 0.02. Deze parameters zijn gebaseerd op de controlepraktijken uit het eerdere onderzoek naar Afferden. We hebben daar overigens alleen data per jaar, deze data worden gegenereerd per kwartaal. Het is niet helemaal duidelijk of de variatie op kwartaalbasis groter is. \n\nLet op: Om de analyse te doen hebben we nodig:\n\n-   Aantal verwijzingen per praktijk (Zorgdomein)\n-   Aantal ingeschreven patienten per kwartaal \n\n\n## Trend in de tijd\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Kies een tijdtrend (structurele toename/afname per kwartaal) die voor alle praktijken hetzelfde is. \n\nKwartaaleffect <- -0.01\n```\n:::\n\n\nHet is natuurlijk mogelijk dat er een natuurlijke trend (onafhankelijk van de interventie) in het aantal verwijzingen is. In de data van de controlepraktijken in het onderzoek van Afferden lijken de verwijzingen bij alle praktijken over de tijd licht af te nemen. Een tijdtrend bemoeilijkt mogelijk het schatten van het effect, vandaar dat we ook een tijdtrend hebben toegevoegd. Deze tijdtrend kan in het bovenstaande blokje worden aangepast.\n\n## Effect grootte en minimum effect\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Kies effect grootte\n\nEffect <- -0.04   # 0.04 is ongeveer 10% minder verwijzingen\n\n# Kies minimum effect\n\nGrens <- 0\n\n\n# Bereken percentage minder verwijzingen voor in de tekst\n\nRE <- (Effect/0.4) * 100\n```\n:::\n\n\nWe voegen handmatig een effect toe in onze data. In deze analyse hebben we een effect van ongeveer -10% verwijzingen toegevoegd. Het getal dat we uit onze analyse moeten krijgen is -0.04. Dit effect kan groter of kleiner worden gemaakt in het bovenstaande codeblokje. \n\nDaarnaast kunnen we een minimumeffect bepalen. In deze analyse is het minimumeffect wat we willen zien gesteld op 0. \n\nIn onze simulatie krijgen we de volledige kansverdeling op van effectgroottes. In het algemeen (maar niet noodzakelijk) zijn die kansverdelingen redelijk normaal verdeeld. We kunnen dan het gemiddelde effect schatten. Deze schatting moet ongeveer gelijk zijn aan het effect wat we in onze simulatie hebben ingebracht. In dit geval moet dit gemiddelde dus in buurt liggen van -0.04. Omdat we een volledige kansverdeling hebben, kunnen we ook iets over hoe groot de kans is op een bepaald minimumeffect.\n\nStel dat we het minimumeffect op 0 stellen. Dan kunnen we op basis van de kansverdeling zeggen: Er is x% kans dat het aantal verwijzingen is afgenomen.  \n\n## Aantal simulaties\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Kies het aantal regressies dat gerund moet worden\n\n\nIterations <- 20\n```\n:::\n\n\n\nTenslotte kunnen we het aantal regressies bepalen door het aantal Iterations in bovenstaand codeblokje aan te passen. De regressies kosten veel tijd en geheugen en de plots over de uitkomsten nemen veel ruimte in beslag. Daarom willen we adviseren het aantal iteraties niet te hoog te maken. In deze analyse is het aantal regressies bepaald op 20.\n\n\n# Genereren van basisdata en uitvoeren regressies\n\n## Basisdata\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123) # reproduceerbaarheid\n\ndf1 <- tibble(id = 1:(IP + CP)) %>% # \n             mutate(Interventie = ifelse(test = id <= 2, yes = 1, no = 0 )) %>%\n             # Maak gemiddelde verwijzingen per ingeschreven patient voor eerste kwartaal aan (de basis) \n             # om straks de evaluatie inzichtelijk te houden kiezen we voor de interventiepraktijken hetzelfde basispercentage\n             mutate(K1 = c(rep(40, each = IP), sample(x = 37:43, size = 3))/100) \n```\n:::\n\n\nIn de bovenstaande code worden de basisdata gegenereerd. Praktijken worden ingedeeld als interventie of controlepraktijk, en voor iedere prakijk zetten we het gemiddeld aantal verwijzingen voor het eerste kwartaal. We simuleren straks 11 andere kwartalen, waarbij we de interventie in kwartaal 9 laten beginnen. \n\n\n## Simulatie\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Hier simuleren we (op basis van het gekozen aantal regressies) steeds opnieuw data en runnen dan regressies\n\nfullrun <- 0\n\nif(fullrun){\n  \n# maak lege vectoren voor estimate and CI's\nnames <- c(\"9\", \"10\", \"11\", \"12\")\nvar_lst <- sapply(paste0(\"Estimate_\", names), function(x) assign(x, NULL))\nvar_lst2 <-sapply(paste0(\"upper_\", names), function(x) assign(x,NULL))\nvar_lst3 <-sapply(paste0(\"lower_\", names), function(x) assign(x,NULL))\n\nlist2env(var_lst, .GlobalEnv)\nlist2env(var_lst2, .GlobalEnv)\nlist2env(var_lst3, .GlobalEnv)\n\n# make lege tibble aan voor posterior draws\n\nsamples <- tibble()\n\n# Hier begint de for-loop\n\nfor(i in 1:Iterations){\n  \n# wisselende set.seeds voor reproduceerbaarheid\n\nset.seed(1000 + i * 10)\n\n# maak tibble met andere kwartalen\n\ndf <- df1 %>%\n  mutate(K2 = rnorm(n = 5, mean = (1 + Kwartaaleffect) * K1, sd = 0.02),\n         K3 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^2 * K1, sd = 0.02),\n         K4 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^3 * K1, sd = 0.02),\n         K5 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^4 * K1, sd = 0.02),\n         K6 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^5 * K1, sd = 0.02),\n         K7 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^6 * K1, sd = 0.02),\n         K8 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^7 * K1, sd = 0.02),\n         # nu begint de interventie\n         K9 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^8 * K1, sd = 0.02) + Effect * Interventie,\n         K10 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^9 * K1, sd = 0.02) + Effect * Interventie,\n         K11 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^10 * K1, sd = 0.02) + Effect * Interventie,\n         K12 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^11 * K1, sd = 0.02) + Effect * Interventie) %>%\n  # lang maken data\n         pivot_longer(cols = K1:K12, names_to = \"Kwartaal\", \n                      values_to = \"Verwijzingen\") %>%\n   # maak kwartaal numeriek om de interventievariabele te kunnen maken\n         mutate(Kwartaal = str_sub(Kwartaal, start = 2)) %>%\n   # maak onze effect variabelen\n         mutate(DiD_9 = ifelse(test = as.numeric(Kwartaal) == 9 & Interventie == 1, \n                             yes = 1,\n                             no = 0)) %>%\n         mutate(DiD_10 = ifelse(test = as.numeric(Kwartaal) == 10 & Interventie == 1, \n                             yes = 1,\n                             no = 0)) %>%\n         mutate(DiD_11 = ifelse(test = as.numeric(Kwartaal) == 11 & Interventie == 1, \n                             yes = 1,\n                             no = 0)) %>%\n         mutate(DiD_12 = ifelse(test = as.numeric(Kwartaal) == 12 & Interventie == 1, \n                             yes = 1,\n                             no = 0)) %>%\n      # we maken kwartaal een factor\n          mutate(Kwartaal = as.factor(Kwartaal))\n      \n\n# Formule\n\nFormula <- \"Verwijzingen ~ 0 + Intercept + id + Kwartaal + DiD_9 + DiD_10 + DiD_11 + DiD_12\"\n\n\n# Priors\n\n## niet informatieve priors\n\nprior1 <- c(set_prior(\"normal(0.4, 0.04)\", class = \"b\", coef = \"Intercept\"),\n            set_prior(\"normal(0, 0.05)\", class = \"b\", coef = \"DiD_9\"),\n            set_prior(\"normal(0, 0.05)\", class = \"b\", coef = \"DiD_10\"),\n            set_prior(\"normal(0, 0.05)\", class = \"b\", coef = \"DiD_11\"),\n            set_prior(\"normal(0, 0.05)\", class = \"b\", coef = \"DiD_12\"))\n\n\nreg1 <- brm(\n  formula = Formula,\n  prior = prior1,\n  warmup = 1000,\n  iter = 2500,\n  data = df,\n  chains = 4, \n  cores = 6,\n  init = \"random\",\n  control = list(adapt_delta = 0.8, max_treedepth = 12),\n  seed = 123,\n  backend = \"cmdstanr\",\n  )\n\n\n\n# vul lege vectoren met samenvattende getallen (estimate en CI) \n\nEstimate_9[i] = fixef(reg1)[14,1]\nlower_9[i] = fixef(reg1)[14,3]\nupper_9[i] = fixef(reg1)[14,4]\n\nEstimate_10[i] = fixef(reg1)[15,1]\nlower_10[i] = fixef(reg1)[15,3]\nupper_10[i] = fixef(reg1)[15,4]\n\nEstimate_11[i] = fixef(reg1)[16,1]\nlower_11[i] = fixef(reg1)[16,3]\nupper_11[i] = fixef(reg1)[16,4]\n\nEstimate_12[i] = fixef(reg1)[17,1]\nlower_12[i] = fixef(reg1)[17,3]\nupper_12[i] = fixef(reg1)[17,4]\n\n## Maak per kwartaal een tibble\n\n\nResults_9 <- tibble(Estimate = Estimate_9, lower = lower_9, upper = upper_9) %>%\n            mutate(Kwartaal = \"Kwartaal 9\")\n\nResults_10 <- tibble(Estimate = Estimate_10, lower = lower_10, upper = upper_10)%>%\n            mutate(Kwartaal = \"Kwartaal 10\")\n\nResults_11 <- tibble(Estimate = Estimate_11, lower = lower_11, upper = upper_11)%>%\n            mutate(Kwartaal = \"Kwartaal 11\")\n\nResults_12 <- tibble(Estimate = Estimate_12, lower = lower_12, upper = upper_12) %>%\n            mutate(Kwartaal = \"Kwartaal 12\")\n\n## Voeg de tibbles samen\n\nResults = rbind(Results_9, Results_10, Results_11, Results_12)\n\n\n# posterior draws\n\nsamples_temp <- tibble(as_draws_df(reg1)) %>%\n  mutate(Run = as.factor(i))\n\nsamples <- samples %>%\n  rbind(samples_temp)\n\n}\n\nsaveRDS(Results, \"Results.RDS\")\nsaveRDS(samples, \"samples.RDS\")\n\n\n} else {\n\nResults <- readRDS(\"Results.RDS\")\nsamples <- readRDS(\"samples.RDS\")\n\n  \n}\n```\n:::\n\n\n\nIn de bovenstaande code voeren we herhaaldelijk simulaties uit, waarbij we telkens iets andere gegevens genereren. We simuleren de gemiddelde verwijzingen per geregistreerde patiënt voor de kwartalen 2 tot en met 12, waarbij we wat willekeurige variatie en een tijdtrend introduceren rondom het getal dat geldt voor het eerste kwartaal. Deze toegevoegde variatie (aangeduid als ruis en vastgesteld op 0.02) komt neer op ongeveer 5% van het aantal verwijzingen en is gebaseerd op de gegevens van controlepraktijken uit het Afferden-onderzoek.\n\nHierna voeren we voor elke gesimuleerde dataset een Bayesiaanse regressie uit en bewaren we de resultaten. Bij het uitvoeren van deze regressie gaan we uit van een initiële en enigszins conservatieve verwachting dat de interventie geen effect heeft. Niettemin laten we wel ruimte voor onzekerheid. We stellen daarom een effect waarvan de kansverdeling normaal verdeeld is rondom 0, met een standaarddeviatie van 0.05. Dit houdt in dat we ongeveer 95% kans verwachten dat het effect zich tussen -0.1 en 0.1 bevindt. Dit vertaalt zich in percentages naar een effect van ongeveer plus of min 25% op het aantal verwijzingen. Zeer grote effecten (zoals in eerder onderzoek waargenomen in Afferden) worden met deze initiële verwachting als zeer onwaarschijnlijk beschouwd. Ter volledigheid hebben we ook een alternatieve initiële verwachting getest, waarin we een groot effect verwachten. Dit blijkt maar in beperkte mate van invloed te zijn op de resultaten. Zie hierna in de paragraaf over de invloed van een andere prior.\n\n# Visualisaties van de schattingen\n\nWe geven de resultaten van de regressies per kwartaal grafisch weer. Elke grafiek toont per iteratie de schatting van het effect. Je ziet deze weergegeven als een kansverdeling. In de kansverdeling vertegenwoordigt de zwarte verticale lijn het geschatte gemiddelde effect. De groene verticale lijn markeert het vastgestelde effect zoals we eerder handmatig hebben ingevoerd. We verwachten dat de schattingen van het effect dicht bij het vastgestelde effect liggen. Eerder hebben we ingesteld of het effect positief (minder verwijzingen) of negatief is (meer verwijzingen). De volgende interpretatie geldt wanneer het effect positief is ingesteld: Een zwarte lijn links van de groene lijn geeft aan dat het werkelijke effect wordt overschat. Wanneer de zwarte lijn rechts van de groene lijn staat, wordt het werkelijke effect onderschat. \n\nDe verticale rood gestippelde lijn geeft een nul-effect aan. Aan de rechterkant van de kansverdelingen staat in blauwe tekst weergegeven wat de kans is dat het effect minstens gelijk is aan, of kleiner dan, het gewenste minimumeffect waarin we interesse hebben. In dit geval is het minimumeffect gesteld op 0.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSubplottitle <-  paste0(\"De kansverdeling van het geschatte effect per simulatie\\nen in het blauw de kans dat het effect kleiner is dan \", Grens)\n\nsamples_grens9 <- samples %>%\n  mutate(GrensO = ifelse(test = b_DiD_9 < Grens,\n                         yes = 1,\n                         no = 0)) %>%\n  group_by(Run) %>%\n  summarise(Percentage1 = mean(GrensO)) %>%\n  ungroup() %>%\n  mutate(Percentage = paste0(round(Percentage1 * 100, 0), \" %\"))%>%\n  mutate(Run_extra = as.numeric(Run))\n\n\n\nggplot(data = samples, aes(x = b_DiD_9, \n                             y = Run)) +\n  geom_density_ridges2(scale = 0.85, quantile_lines=TRUE,\n                      quantile_fun=function(x,...)mean(x)) +\n  geom_vline(xintercept = 0, color = \"firebrick\", linetype = \"dashed\") +\n  geom_vline(xintercept = Effect, color = \"darkgreen\") +\n  theme_bw() +\n  theme(legend.position = \"none\") +\n  labs(y = \" \", x = \"Geschatte effect\",\n       title = \"Kwartaal 9\",\n       subtitle = Subplottitle) +\n  geom_text(data = samples_grens9, aes(x = 0.05, y = (as.numeric(Run) + 0.25), label = Percentage),\n            size = 2.5, color = \"steelblue\") +\n  xlim(-0.1, 0.1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plotk9-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsamples_grens10 <- samples %>%\n  mutate(GrensO = ifelse(test = b_DiD_10 < Grens,\n                         yes = 1,\n                         no = 0)) %>%\n  group_by(Run) %>%\n  summarise(Percentage1 = mean(GrensO)) %>%\n  ungroup() %>%\n  mutate(Percentage = paste0(round(Percentage1 * 100, 0), \" %\"))%>%\n  mutate(Run_extra = as.numeric(Run))\n\n\n\nggplot(data = samples, aes(x = b_DiD_10, \n                             y = Run)) +\n  geom_density_ridges2(scale = 0.85, quantile_lines=TRUE,\n                      quantile_fun=function(x,...)mean(x)) +\n  geom_vline(xintercept = 0, color = \"firebrick\", linetype = \"dashed\") +\n  geom_vline(xintercept = Effect, color = \"darkgreen\") +\n  theme_bw() +\n  theme(legend.position = \"none\") +\n  labs(y = \" \", x = \"Geschatte effect\",\n       title = \"Kwartaal 10\",\n       subtitle = Subplottitle) +\n  geom_text(data = samples_grens10, aes(x = 0.05, y = (as.numeric(Run) + 0.25), label = Percentage),\n            size = 2.5, color = \"steelblue\") +\n  xlim(-0.1, 0.1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plotk10-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsamples_grens11 <- samples %>%\n  mutate(GrensO = ifelse(test = b_DiD_11 < Grens,\n                         yes = 1,\n                         no = 0)) %>%\n  group_by(Run) %>%\n  summarise(Percentage1 = mean(GrensO)) %>%\n  ungroup() %>%\n  mutate(Percentage = paste0(round(Percentage1 * 100, 0), \" %\"))%>%\n  mutate(Run_extra = as.numeric(Run))\n\n\n\nggplot(data = samples, aes(x = b_DiD_11, \n                             y = Run)) +\n  geom_density_ridges2(scale = 0.85, quantile_lines=TRUE,\n                      quantile_fun=function(x,...)mean(x)) +\n  geom_vline(xintercept = 0, color = \"firebrick\", linetype = \"dashed\") +\n  geom_vline(xintercept = Effect, color = \"darkgreen\") +\n  theme_bw() +\n  theme(legend.position = \"none\") +\n  labs(y = \" \", x = \"Geschatte effect\",\n       title = \"Kwartaal 11\",\n       subtitle = Subplottitle) +\n  geom_text(data = samples_grens11, aes(x = 0.05, y = (as.numeric(Run) + 0.25), label = Percentage),\n            size = 2.5, color = \"steelblue\") +\n  xlim(-0.1, 0.1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plotk11-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsamples_grens12 <- samples %>%\n  mutate(GrensO = ifelse(test = b_DiD_12 < Grens,\n                         yes = 1,\n                         no = 0)) %>%\n  group_by(Run) %>%\n  summarise(Percentage1 = mean(GrensO)) %>%\n  ungroup() %>%\n  mutate(Percentage = paste0(round(Percentage1 * 100, 0), \" %\"))%>%\n  mutate(Run_extra = as.numeric(Run))\n\n\nggplot(data = samples, aes(x = b_DiD_12, \n                             y = Run)) +\n  geom_density_ridges2(scale = 0.85, quantile_lines=TRUE,\n                      quantile_fun=function(x,...)mean(x)) +\n  geom_vline(xintercept = 0, color = \"firebrick\", linetype = \"dashed\") +\n  geom_vline(xintercept = Effect, color = \"darkgreen\") +\n  theme_bw() +\n  theme(legend.position = \"none\") +\n  labs(y = \" \", x = \"Geschatte effect\",\n       title = \"Kwartaal 12\",\n       subtitle = Subplottitle) +\n  geom_text(data = samples_grens12, aes(x = 0.05, y = (as.numeric(Run) + 0.25), label = Percentage),\n            size = 2.5, color = \"steelblue\") +\n  xlim(-0.1, 0.1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plotk12-1.png){width=672}\n:::\n:::\n\n\n# De invloed van andere initiële verwachtingen (priors)\n\nWe hebben dezelfde simulatie opnieuw uitgevoerd zoals hierboven beschreven. De enige wijziging die we hebben aangebracht, is dat we nu een optimistischere initiële verwachting (prior) hanteren. Onze initiële verwachting is nu dat de interventie een effect heeft van -0.2, wat betekent dat de interventie leidt tot een daling van ongeveer 50% van het gemiddelde aantal verwijzingen per geregistreerde patiënt (bij een gemiddeld aantal verwijzingen van 0.4). Doordat we een aanzienlijke mate van onzekerheid toekennen (aangegeven door een standaarddeviatie van 0.2), is deze optimistische verwachting wel flexibel en vatbaar voor aanpassing op basis van de verzamelde gegevens. \n\nIn onderstaande grafiek zie je het effect van deze optimistische prior ten opzichte van de conservatieve prior.We presenteren de gemiddeldes en standaarddeviaties bij beide priors. Bij een werkelijk effect van -0.04 (een 10% afname) geeft de optimistische prior een kleine overschatting van het effect, terwijl de conservatieve prior iets onderschat. Het kiezen van de beste prior is afhankelijk van onze wensen bij het onderzoek. Omdat we het bij dit onderzoek vooral belangrijk vinden om het effect niet te overschatten, zullen we bij onze belangrijkste analyse een conservatieve prior hanteren.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Hier simuleren we (op basis van het gekozen aantal regressies) steeds opnieuw data en runnen dan regressies\n\nfullrun <- 0\n\nif(fullrun){\n  \n# maak lege vectoren voor estimate and CI's\nnames <- c(\"9\", \"10\", \"11\", \"12\")\nvar_lst <- sapply(paste0(\"Estimate_\", names), function(x) assign(x, NULL))\nvar_lst2 <-sapply(paste0(\"upper_\", names), function(x) assign(x,NULL))\nvar_lst3 <-sapply(paste0(\"lower_\", names), function(x) assign(x,NULL))\n\nlist2env(var_lst, .GlobalEnv)\nlist2env(var_lst2, .GlobalEnv)\nlist2env(var_lst3, .GlobalEnv)\n\n# make lege tibble aan voor posterior draws\n\nsamples <- tibble()\n\n# Hier begint de for-loop\n\nfor(i in 1:Iterations){\n  \n# wisselende set.seeds voor reproduceerbaarheid\n\nset.seed(1000 + i * 10)\n\n# maak tibble met andere kwartalen\n\ndf <- df1 %>%\n  mutate(K2 = rnorm(n = 5, mean = (1 + Kwartaaleffect) * K1, sd = 0.02),\n         K3 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^2 * K1, sd = 0.02),\n         K4 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^3 * K1, sd = 0.02),\n         K5 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^4 * K1, sd = 0.02),\n         K6 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^5 * K1, sd = 0.02),\n         K7 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^6 * K1, sd = 0.02),\n         K8 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^7 * K1, sd = 0.02),\n         # nu begint de interventie\n         K9 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^8 * K1, sd = 0.02) + Effect * Interventie,\n         K10 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^9 * K1, sd = 0.02) + Effect * Interventie,\n         K11 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^10 * K1, sd = 0.02) + Effect * Interventie,\n         K12 = rnorm(n = 5, mean = (1 + Kwartaaleffect)^11 * K1, sd = 0.02) + Effect * Interventie) %>%\n  # lang maken data\n         pivot_longer(cols = K1:K12, names_to = \"Kwartaal\", \n                      values_to = \"Verwijzingen\") %>%\n   # maak kwartaal numeriek om de interventievariabele te kunnen maken\n         mutate(Kwartaal = str_sub(Kwartaal, start = 2)) %>%\n   # maak onze effect variabelen\n         mutate(DiD_9 = ifelse(test = as.numeric(Kwartaal) == 9 & Interventie == 1, \n                             yes = 1,\n                             no = 0)) %>%\n         mutate(DiD_10 = ifelse(test = as.numeric(Kwartaal) == 10 & Interventie == 1, \n                             yes = 1,\n                             no = 0)) %>%\n         mutate(DiD_11 = ifelse(test = as.numeric(Kwartaal) == 11 & Interventie == 1, \n                             yes = 1,\n                             no = 0)) %>%\n         mutate(DiD_12 = ifelse(test = as.numeric(Kwartaal) == 12 & Interventie == 1, \n                             yes = 1,\n                             no = 0)) %>%\n      # we maken kwartaal een factor\n          mutate(Kwartaal = as.factor(Kwartaal))\n      \n\n# Formule\n\nFormula <- \"Verwijzingen ~ 0 + Intercept + id + Kwartaal + DiD_9 + DiD_10 + DiD_11 + DiD_12\"\n\n\n# Priors\n\n## informatieve priors\n\nprior2 <- c(set_prior(\"normal(0.4, 0.04)\", class = \"b\", coef = \"Intercept\"),\n            set_prior(\"normal(-0.2, 0.2)\", class = \"b\", coef = \"DiD_9\"),\n            set_prior(\"normal(-0.2, 0.2)\", class = \"b\", coef = \"DiD_10\"),\n            set_prior(\"normal(-0.2, 0.2)\", class = \"b\", coef = \"DiD_11\"),\n            set_prior(\"normal(-0.2, 0.2)\", class = \"b\", coef = \"DiD_12\"))\n\n\nreg1 <- brm(\n  formula = Formula,\n  prior = prior2,\n  warmup = 1000,\n  iter = 2500,\n  data = df,\n  chains = 4, \n  cores = 6,\n  init = \"random\",\n  control = list(adapt_delta = 0.8, max_treedepth = 12),\n  seed = 123,\n  backend = \"cmdstanr\",\n  )\n\n\n\n# vul lege vectoren met samenvattende getallen (estimate en CI) \n\nEstimate_9[i] = fixef(reg1)[14,1]\nlower_9[i] = fixef(reg1)[14,3]\nupper_9[i] = fixef(reg1)[14,4]\n\nEstimate_10[i] = fixef(reg1)[15,1]\nlower_10[i] = fixef(reg1)[15,3]\nupper_10[i] = fixef(reg1)[15,4]\n\nEstimate_11[i] = fixef(reg1)[16,1]\nlower_11[i] = fixef(reg1)[16,3]\nupper_11[i] = fixef(reg1)[16,4]\n\nEstimate_12[i] = fixef(reg1)[17,1]\nlower_12[i] = fixef(reg1)[17,3]\nupper_12[i] = fixef(reg1)[17,4]\n\n## Maak per kwartaal een tibble\n\n\nResults_9 <- tibble(Estimate = Estimate_9, lower = lower_9, upper = upper_9) %>%\n            mutate(Kwartaal = \"Kwartaal 9\")\n\nResults_10 <- tibble(Estimate = Estimate_10, lower = lower_10, upper = upper_10)%>%\n            mutate(Kwartaal = \"Kwartaal 10\")\n\nResults_11 <- tibble(Estimate = Estimate_11, lower = lower_11, upper = upper_11)%>%\n            mutate(Kwartaal = \"Kwartaal 11\")\n\nResults_12 <- tibble(Estimate = Estimate_12, lower = lower_12, upper = upper_12) %>%\n            mutate(Kwartaal = \"Kwartaal 12\")\n\n## Voeg de tibbles samen\n\nResults = rbind(Results_9, Results_10, Results_11, Results_12)\n\n\n# posterior draws\n\nsamples_temp <- tibble(as_draws_df(reg1)) %>%\n  mutate(Run = as.factor(i))\n\nsamples <- samples %>%\n  rbind(samples_temp)\n\n}\n\nsaveRDS(Results, \"Results2.RDS\")\nsaveRDS(samples, \"samples2.RDS\")\n\n\n} else {\n\nResults2 <- readRDS(\"Results2.RDS\")\nsamples2 <- readRDS(\"samples2.RDS\")\n\n  \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nRR <- Results %>%\n  group_by(Kwartaal) %>%\n  summarise(ME = mean(Estimate), ML = mean(lower), MU = mean(upper)) %>%\n  ungroup() %>%\n  mutate(Prior = \"conservatief\")\n\n\nRR2 <-Results2 %>% \n  group_by(Kwartaal) %>%\n  summarise(ME = mean(Estimate), ML = mean(lower), MU = mean(upper)) %>%\n  ungroup() %>%\n  mutate(Prior = \"overdreven\\noptimistisch\")\n\nRR3 <- rbind(RR, RR2) \n\nggplot(data = RR3, aes(x = ML, xend = MU, y = Prior, yend = Prior)) +\n  geom_segment() +\n  geom_point(aes(x = ME, y = Prior), size = 2) +\n  facet_wrap(~factor(Kwartaal, levels=c(\"Kwartaal 9\",\n                                        \"Kwartaal 10\",\n                                        \"Kwartaal 11\",\n                                        \"Kwartaal 12\"))) +\n  geom_vline(xintercept = 0, color = \"firebrick\", linetype = \"dashed\") +\n  geom_vline(xintercept = Effect, color = \"darkgreen\") +\n  xlim(-0.2, 0.2) +\n  theme_bw() +\n  theme(legend.position = \"none\") +\n  labs(y = \"\", x = \"Geschatte effect\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/vergelijkingpriors-1.png){width=672}\n:::\n:::\n\n\n# Installatie-instructies\n\nWe hebben in ieder geval dit notebook nodig. Daarnaast moet er gratis software worden geinstalleerd:\n\n - Rstudio en R [https://RStudio en R.co/download/rstudio-desktop/](https://posit.co/download/rstudio-desktop/ \"RStudio en R\")\n - Stan <https://learnb4ss.github.io/learnB4SS/articles/install-brms.html> (Stan wordt gebruikt voor de bayesiaanse schatting)\n\nJe hoeft alleen RStudio te openen. Als je Rstudio voor de eerste keer installeert, dan vraagt hij vermoedelijk om een aantal packages (verzamelingen van functies) te installeren. Het is noodzakelijk dat te doen. RStudio installeert deze packages zelf.\n\nDaarnaast moeten er nog een aantal packages (zie de code `library()` in het settings codeblokje bovenaan) geinstalleerd worden. Dat is maar 1 keer nodig. Omdat te doen, moet je het hekje voor `install.packages()` weghalen en de code runnen met het playknopje. Daarna kan het hekje weer worden teruggezet (dan wordt de code niet gerund).\n\nMet het knopje \"Render\" (naast de blauwe pijl, ongeveer in het midden in de menubalk) kun je deze html opnieuw genereren. Let op: De schattingen kosten veel tijd. Daarom is er een functie gemaakt (met de naam `fullrun()`). De aanbeveling is om eerst de 2 simulatie codeblokje na een verandering te runnen met `fullrun <- 1` en daarna fullrun weer op `fullrun <- 0` te zetten en iedere simulatie apart te runnen. Nadat je dat hebt gedaan, kun je het knopje Render gebruiken om een nieuwe html te maken.\n\n\n\n# Het schrijven van blogs\n\n\n## Inleiding\n\nDit is een blog over het schrijven van blogs.\n\n## Deel 1\n\nHier komt deel 1 van het blog.\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}